{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline,T5Tokenizer, T5ForConditionalGeneration\n",
    "import pandas as pd\n",
    "from numpy import average, round, nan\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#uncomment to get reproducable paraphrase generations\n",
    "def random_state(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random_state(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#Init models (make sure you init ONLY once if you integrate this to your code)\n",
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=True)\n",
    "\n",
    "#device = \"cuda\"\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "\n",
    "model_gpt = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\").to(device)\n",
    "\n",
    "\n",
    "tokenizer_t5 = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Translator\n",
    "translator_en_fr = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\", max_length=512)\n",
    "translator_fr_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-tc-big-fr-en\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(\n",
    "    question,\n",
    "    num_beams=4,\n",
    "    num_beam_groups=4,\n",
    "    num_return_sequences=4,\n",
    "    repetition_penalty=10.0,\n",
    "    diversity_penalty=3.0,\n",
    "    no_repeat_ngram_size=2,\n",
    "    temperature=0.5,\n",
    "    max_length=128\n",
    "):\n",
    "    input_ids = tokenizer_gpt(\n",
    "        f'paraphrase: {question}',\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    ).input_ids.to(device)\n",
    "    \n",
    "    outputs = model_gpt.generate(\n",
    "        input_ids, temperature=temperature, repetition_penalty=repetition_penalty,\n",
    "        num_return_sequences=num_return_sequences, no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "        num_beams=num_beams, num_beam_groups=num_beam_groups,\n",
    "        max_length=max_length, diversity_penalty=diversity_penalty\n",
    "    )\n",
    "\n",
    "    res = tokenizer_gpt.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_phrases_t5(df, input_column, output_column):\n",
    "    \"\"\"\n",
    "    Generate output phrases by paraphrasing the input phrases.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame containing the input phrases.\n",
    "    - input_column (str): The name of the column in the DataFrame that contains the input phrases.\n",
    "    - output_column (str): The name of the column in the DataFrame to store the output phrases.\n",
    "    - paraphrase (function): The function used to paraphrase the input phrases.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The DataFrame with the original input phrases and the generated output phrases.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an empty list to store data\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each input phrase\n",
    "    for sentence in df[input_column]:\n",
    "        para_phrases = paraphrase(sentence)\n",
    "        data.append({input_column: sentence, output_column: para_phrases})\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    new_df = pd.DataFrame(data)\n",
    "\n",
    "    # Merge new_df with the original DataFrame df\n",
    "    outro_df = pd.concat([df, new_df[output_column]], axis=1)\n",
    "    outro_df = pd.concat([outro_df, pd.DataFrame(outro_df[output_column].values.tolist())], axis=1)\n",
    "    return outro_df\n",
    "\n",
    "def generate_output_phrases_parrot(df, input_column, output_column):\n",
    "    \"\"\"\n",
    "    Generate output phrases by paraphrasing the input phrases.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The input DataFrame containing the input phrases.\n",
    "    - input_column (str): The name of the column in the DataFrame that contains the input phrases.\n",
    "    - output_column (str): The name of the column in the DataFrame to store the output phrases.\n",
    "    - paraphrase (function): The function used to paraphrase the input phrases.\n",
    "\n",
    "    Returns:\n",
    "    - df (pandas.DataFrame): The DataFrame with the original input phrases and the generated output phrases.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an empty list to store data\n",
    "    data = []\n",
    "    x = -1\n",
    "    # Iterate over each input phrase\n",
    "    for sentence in df[input_column]:\n",
    "        para_phrases = parrot.augment(input_phrase=sentence, \n",
    "                                      max_return_phrases = 3)\n",
    "        if para_phrases == None:\n",
    "           data.append({input_column: sentence, output_column: para_phrases})\n",
    "        else:\n",
    "            para_frases = list(list(zip(*para_phrases))[0])\n",
    "            data.append({input_column: sentence, output_column: para_frases})\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    new_df = pd.DataFrame(data)\n",
    "\n",
    "    # Merge new_df with the original DataFrame df\n",
    "    outro_df = pd.concat([df, new_df[output_column]], axis=1)\n",
    "\n",
    "    # Verificar se há valores nulos na coluna 'Parrot_paraphrased_filled_sentence'\n",
    "    has_null_values = outro_df[output_column].isnull().any()\n",
    "\n",
    "    # Se houver valores nulos, você pode escolher lidar com eles de várias maneiras\n",
    "    if has_null_values:\n",
    "        # Ou substituir os valores nulos por uma string vazia, por exemplo\n",
    "        outro_df[output_column].fillna('', inplace=True)\n",
    "    outro_df = pd.concat([outro_df, pd.DataFrame(outro_df[output_column].values.tolist())], axis=1)\n",
    "    return outro_df\n",
    "\n",
    "def rename_numeric_columns(df, replacement_prefix='Column_'):\n",
    "    \"\"\"\n",
    "    Renomeia as colunas que consistem apenas de valores numéricos.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df (pandas.DataFrame): O DataFrame que contém as colunas a serem renomeadas.\n",
    "    - replacement_prefix (str): O prefixo a ser usado para os novos nomes das colunas.\n",
    "\n",
    "    Retorna:\n",
    "    - df (pandas.DataFrame): O DataFrame com as colunas renomeadas.\n",
    "    \"\"\"\n",
    "\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        # Verificar se o nome da coluna pode ser convertido para um número inteiro\n",
    "        try:\n",
    "            col_int = int(col)\n",
    "            new_columns.append(replacement_prefix + str(col_int))\n",
    "        except ValueError:\n",
    "            new_columns.append(col)\n",
    "\n",
    "    # Renomear as colunas do DataFrame\n",
    "    df.columns = new_columns\n",
    "\n",
    "    return df\n",
    "\n",
    "def replace_masked_sentence(df, mask_column, label_column, new_column):\n",
    "    df[new_column] = df.apply(lambda row: str(row[mask_column]).replace(\"[MASK]\", str(row[label_column])), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def substituir_palavras(texto, palavras_substituir, substituto=\"[MASK]\"):\n",
    "    if isinstance(texto, str) and texto is not None:\n",
    "        for palavra in palavras_substituir:\n",
    "            # Usando expressão regular para substituir apenas a primeira ocorrência da palavra\n",
    "            texto = re.sub(r'\\b' + re.escape(palavra) + r'\\b', substituto, texto, count=1)\n",
    "        return texto\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Born In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m parafrase_t5_bornIn \u001b[38;5;241m=\u001b[39m rename_numeric_columns(parafrase_t5_bornIn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT5_paraphrased_filled_sentence_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m parafrase_t5_bornIn\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilled_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT5_paraphrased_filled_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m parafrase_parrot_bornIn \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_output_phrases_parrot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bornIn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilled_sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mParrot_paraphrased_filled_sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m parafrase_parrot_bornIn \u001b[38;5;241m=\u001b[39m rename_numeric_columns(parafrase_parrot_bornIn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParrot_paraphrased_filled_sentence_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m parafrase_parrot_bornIn\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilled_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParrot_paraphrased_filled_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m, in \u001b[0;36mgenerate_output_phrases_parrot\u001b[0;34m(df, input_column, output_column)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Iterate over each input phrase\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m df[input_column]:\n\u001b[0;32m---> 50\u001b[0m     para_phrases \u001b[38;5;241m=\u001b[39m \u001b[43mparrot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_phrase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_return_phrases\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m para_phrases \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m        data\u001b[38;5;241m.\u001b[39mappend({input_column: sentence, output_column: para_phrases})\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/parrot/parrot.py:112\u001b[0m, in \u001b[0;36mParrot.augment\u001b[0;34m(self, input_phrase, use_gpu, diversity_ranker, do_diverse, max_return_phrases, max_length, adequacy_threshold, fluency_threshold)\u001b[0m\n\u001b[1;32m    102\u001b[0m   preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    103\u001b[0m         input_ids,\n\u001b[1;32m    104\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m         num_return_sequences\u001b[38;5;241m=\u001b[39mmax_return_phrases)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 112\u001b[0m   preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m          \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m          \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m          \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m          \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m          \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_return_phrases\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    122\u001b[0m paraphrases\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m preds:\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/generation/utils.py:1758\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1751\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1752\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1753\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1754\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1755\u001b[0m     )\n\u001b[1;32m   1757\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1758\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1759\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/generation/utils.py:2397\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2394\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2396\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2397\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2405\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1740\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1737\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1740\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:1107\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1093\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1094\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         output_attentions,\n\u001b[1;32m   1105\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:687\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    697\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:594\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    585\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    592\u001b[0m ):\n\u001b[1;32m    593\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 594\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    604\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:536\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m         position_bias\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     position_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# if key and values are already calculated\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# we want only the last query position bias\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:436\u001b[0m, in \u001b[0;36mT5Attention.compute_bias\u001b[0;34m(self, query_length, key_length, device)\u001b[0m\n\u001b[1;32m    434\u001b[0m memory_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(key_length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m    435\u001b[0m relative_position \u001b[38;5;241m=\u001b[39m memory_position \u001b[38;5;241m-\u001b[39m context_position  \u001b[38;5;66;03m# shape (query_length, key_length)\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m relative_position_bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_relative_position_bucket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# shape (query_length, key_length)\u001b[39;49;00m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_decoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_buckets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_attention_num_buckets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_attention_max_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention_bias(relative_position_bucket)  \u001b[38;5;66;03m# shape (query_length, key_length, num_heads)\u001b[39;00m\n\u001b[1;32m    443\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (1, num_heads, query_length, key_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:414\u001b[0m, in \u001b[0;36mT5Attention._relative_position_bucket\u001b[0;34m(relative_position, bidirectional, num_buckets, max_distance)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# now relative_position is in the range [0, inf)\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# half of the buckets are for exact increments in positions\u001b[39;00m\n\u001b[1;32m    413\u001b[0m max_exact \u001b[38;5;241m=\u001b[39m num_buckets \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 414\u001b[0m is_small \u001b[38;5;241m=\u001b[39m \u001b[43mrelative_position\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_exact\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\u001b[39;00m\n\u001b[1;32m    417\u001b[0m relative_position_if_large \u001b[38;5;241m=\u001b[39m max_exact \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    418\u001b[0m     torch\u001b[38;5;241m.\u001b[39mlog(relative_position\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m max_exact)\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(max_distance \u001b[38;5;241m/\u001b[39m max_exact)\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;241m*\u001b[39m (num_buckets \u001b[38;5;241m-\u001b[39m max_exact)\n\u001b[1;32m    421\u001b[0m )\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_born_in.csv'\n",
    "data_bornIn = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_bornIn = data_bornIn[:10]\n",
    "data_bornIn = replace_masked_sentence(data_bornIn, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_bornIn['obj_label'].str.strip()\n",
    "data_bornIn = data_bornIn[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "parafrase_t5_bornIn = generate_output_phrases_t5(data_bornIn, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_bornIn = rename_numeric_columns(parafrase_t5_bornIn, 'T5_paraphrased_filled_sentence_')\n",
    "parafrase_t5_bornIn.drop(columns = ['filled_sentence', 'T5_paraphrased_filled_sentence'], inplace=True, axis=1)\n",
    "\n",
    "parafrase_parrot_bornIn = generate_output_phrases_parrot(data_bornIn, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_bornIn = rename_numeric_columns(parafrase_parrot_bornIn, 'Parrot_paraphrased_filled_sentence_')\n",
    "parafrase_parrot_bornIn.drop(columns = ['filled_sentence','Parrot_paraphrased_filled_sentence'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [coluna for coluna in parafrase_t5_bornIn.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas:\n",
    "    parafrase_t5_bornIn[coluna] = parafrase_t5_bornIn[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_bornIn['obj_label']))\n",
    "\n",
    "colunas = [coluna for coluna in parafrase_parrot_bornIn.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas:\n",
    "    parafrase_parrot_bornIn[coluna] = parafrase_parrot_bornIn[coluna].apply(lambda x: substituir_palavras(x, parafrase_parrot_bornIn['obj_label'].str.lower()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Died In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_died_in.csv'\n",
    "data_diedIn = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_diedIn = data_diedIn[:200]\n",
    "data_diedIn = replace_masked_sentence(data_diedIn, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_diedIn['obj_label'].str.strip()\n",
    "data_diedIn = data_diedIn[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "parafrase_t5_diedIn = generate_output_phrases_t5(data_diedIn, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_diedIn = rename_numeric_columns(parafrase_t5_diedIn, 'T5_paraphrased_filled_sentence_')\n",
    "\n",
    "parafrase_parrot_diedIn = generate_output_phrases_parrot(data_diedIn, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_diedIn = rename_numeric_columns(parafrase_parrot_diedIn, 'Parrot_paraphrased_filled_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [coluna for coluna in parafrase_t5_diedIn.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas:\n",
    "    parafrase_t5_diedIn[coluna] = parafrase_t5_diedIn[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_diedIn[\"obj_label\"]))\n",
    "\n",
    "colunas = [coluna for coluna in parafrase_t5_diedIn.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas:\n",
    "    parafrase_t5_diedIn[coluna] = parafrase_t5_diedIn[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_diedIn[\"obj_label\"].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_theCapital_is.csv'\n",
    "data_capital = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_capital = data_capital[:200]\n",
    "data_capital = replace_masked_sentence(data_capital, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_capital['obj_label'].str.strip()\n",
    "data_capital = data_capital[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "\n",
    "parafrase_t5_capital = generate_output_phrases_t5(data_capital, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_capital = rename_numeric_columns(parafrase_t5_capital, 'T5_paraphrased_filled_sentence_')\n",
    "\n",
    "parafrase_parrot_capital = generate_output_phrases_parrot(data_capital, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_capital = rename_numeric_columns(parafrase_parrot_capital, 'Parrot_paraphrased_filled_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_t5 = [coluna for coluna in parafrase_t5_capital.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_t5:\n",
    "    parafrase_t5_capital[coluna] = parafrase_t5_capital[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_capital[\"obj_label\"]))\n",
    "\n",
    "colunas_parrot = [coluna for coluna in parafrase_parrot_capital.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_parrot:\n",
    "    parafrase_parrot_capital[coluna] = parafrase_parrot_capital[coluna].apply(lambda x: substituir_palavras(x, parafrase_parrot_capital[\"obj_label\"].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_citizen.csv'\n",
    "data_citizen = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_citizen = data_citizen[:200]\n",
    "data_citizen = replace_masked_sentence(data_citizen, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_citizen['obj_label'].str.strip()\n",
    "data_citizen = data_citizen[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "\n",
    "parafrase_t5_citizen = generate_output_phrases_t5(data_citizen, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_citizen = rename_numeric_columns(parafrase_t5_citizen, 'T5_paraphrased_filled_sentence_')\n",
    "\n",
    "parafrase_parrot_citizen = generate_output_phrases_parrot(data_citizen, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_citizen = rename_numeric_columns(parafrase_parrot_citizen, 'Parrot_paraphrased_filled_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_t5 = [coluna for coluna in parafrase_t5_citizen.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_t5:\n",
    "    parafrase_t5_citizen[coluna] = parafrase_t5_citizen[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_citizen[\"obj_label\"]))\n",
    "\n",
    "colunas_parrot = [coluna for coluna in parafrase_parrot_citizen.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_parrot:\n",
    "    parafrase_parrot_citizen[coluna] = parafrase_parrot_citizen[coluna].apply(lambda x: substituir_palavras(x, parafrase_parrot_citizen[\"obj_label\"].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_worksfor.csv'\n",
    "data_worksfor = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_worksfor = data_worksfor[:200]\n",
    "data_worksfor = replace_masked_sentence(data_worksfor, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_worksfor['obj_label'].str.strip()\n",
    "data_worksfor = data_worksfor[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "\n",
    "\n",
    "parafrase_t5_worksfor = generate_output_phrases_t5(data_worksfor, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_worksfor = rename_numeric_columns(parafrase_t5_worksfor, 'T5_paraphrased_filled_sentence_')\n",
    "\n",
    "parafrase_parrot_worksfor = generate_output_phrases_parrot(data_worksfor, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_worksfor = rename_numeric_columns(parafrase_parrot_worksfor, 'Parrot_paraphrased_filled_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_t5 = [coluna for coluna in parafrase_t5_worksfor.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_t5:\n",
    "    parafrase_t5_worksfor[coluna] = parafrase_t5_worksfor[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_worksfor[\"obj_label\"]))\n",
    "\n",
    "colunas_parrot = [coluna for coluna in parafrase_parrot_worksfor.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_parrot:\n",
    "    parafrase_parrot_worksfor[coluna] = parafrase_parrot_worksfor[coluna].apply(lambda x: substituir_palavras(x, parafrase_parrot_worksfor[\"obj_label\"].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/rafael/tese/code/data/novos_data/filtrado_one_language.csv'\n",
    "data_language = pd.read_csv(file).drop(columns=['Unnamed: 0'])\n",
    "#data_language = data_language[:20]\n",
    "data_language = replace_masked_sentence(data_language, 'masked_sentence', 'obj_label', \n",
    "                               'filled_sentence')\n",
    "data_language['obj_label'].str.strip()\n",
    "data_language = data_language[['sub_label', 'template', 'obj_label', \n",
    "                           'masked_sentence', 'filled_sentence']]\n",
    "\n",
    "\n",
    "\n",
    "parafrase_t5_language = generate_output_phrases_t5(data_language, 'filled_sentence', 'T5_paraphrased_filled_sentence')\n",
    "parafrase_t5_language = rename_numeric_columns(parafrase_t5_language, 'T5_paraphrased_filled_sentence_')\n",
    "\n",
    "parafrase_parrot_language = generate_output_phrases_parrot(data_language, 'filled_sentence', 'Parrot_paraphrased_filled_sentence')\n",
    "parafrase_parrot_language = rename_numeric_columns(parafrase_parrot_language, 'Parrot_paraphrased_filled_sentence_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_t5 = [coluna for coluna in parafrase_t5_language.columns if re.match(r'T5_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_t5:\n",
    "    parafrase_t5_language[coluna] = parafrase_t5_language[coluna].apply(lambda x: substituir_palavras(x, parafrase_t5_language[\"obj_label\"]))\n",
    "\n",
    "colunas_parrot = [coluna for coluna in parafrase_parrot_language.columns if re.match(r'Parrot_paraphrased_filled_sentence_[^_]*\\d+', coluna)]\n",
    "# Agora, use o tamanho da lista para determinar quantas colunas você precisa processar\n",
    "for coluna in colunas_parrot:\n",
    "    parafrase_parrot_language[coluna] = parafrase_parrot_language[coluna].apply(lambda x: substituir_palavras(x, parafrase_parrot_language[\"obj_label\"].str.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substituir e deixar apenas uma [MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deixa_uma_mask(sentence, word):\n",
    "    # Substitui a palavra na frase por '[MASK]'\n",
    "    if sentence is None:\n",
    "        return None\n",
    "    elif sentence.count('[MASK]') == 1 or sentence.count('[MASK]') == 0:\n",
    "        return sentence\n",
    "    else:\n",
    "        return sentence.replace('[MASK]', word, (sentence.count('[MASK]'))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Born In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_bornIn.columns[3:]:\n",
    "    parafrase_t5_bornIn[i] = parafrase_t5_bornIn.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_bornIn.columns[3:]:\n",
    "    parafrase_parrot_bornIn[i] = parafrase_parrot_bornIn.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Died In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_diedIn.columns[3:]:\n",
    "    parafrase_t5_diedIn[i] = parafrase_t5_diedIn.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_diedIn.columns[3:]:\n",
    "    parafrase_parrot_diedIn[i] = parafrase_parrot_diedIn.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_capital.columns[3:]:\n",
    "    parafrase_t5_capital[i] = parafrase_t5_capital.apply(lambda row: deixa_uma_mask(row[i],\n",
    "                                                                                   row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_capital.columns[3:]:\n",
    "    parafrase_parrot_capital[i] = parafrase_parrot_capital.apply(lambda row: deixa_uma_mask(row[i],\n",
    "                                                                                   row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Citizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_citizen.columns[3:]:\n",
    "    parafrase_t5_citizen[i] = parafrase_t5_citizen.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_citizen.columns[3:]:\n",
    "    parafrase_parrot_citizen[i] = parafrase_parrot_citizen.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Works For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_worksfor.columns[3:]:\n",
    "    parafrase_t5_worksfor[i] = parafrase_t5_worksfor.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_worksfor.columns[3:]:\n",
    "    parafrase_parrot_worksfor[i] = parafrase_parrot_worksfor.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parafrase_t5_language.columns[3:]:\n",
    "    parafrase_t5_language[i] = parafrase_t5_language.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)\n",
    "    \n",
    "for i in parafrase_parrot_language.columns[3:]:\n",
    "    parafrase_parrot_language[i] = parafrase_parrot_language.apply(lambda row: deixa_uma_mask(row[i], \n",
    "                                         row['obj_label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Born In\n",
    "parafrase_t5_bornIn[\"sentence_length\"]= parafrase_t5_bornIn[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_bornIn = parafrase_t5_bornIn.query('sentence_length < 513')\n",
    "parafrase_t5_bornIn.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_bornIn[\"sentence_length\"]= parafrase_parrot_bornIn[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_bornIn = parafrase_parrot_bornIn.query('sentence_length < 513')\n",
    "parafrase_parrot_bornIn.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "## Died In\n",
    "parafrase_t5_diedIn[\"sentence_length\"]= parafrase_t5_diedIn[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_diedIn = parafrase_t5_diedIn.query('sentence_length < 513')\n",
    "parafrase_t5_diedIn.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_diedIn[\"sentence_length\"]= parafrase_parrot_diedIn[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_diedIn = parafrase_parrot_diedIn.query('sentence_length < 513')\n",
    "parafrase_parrot_diedIn.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "## Capital\n",
    "parafrase_t5_capital[\"sentence_length\"]= parafrase_t5_capital[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_capital = parafrase_t5_capital.query('sentence_length < 513')\n",
    "parafrase_t5_capital.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_capital[\"sentence_length\"]= parafrase_parrot_capital[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_capital = parafrase_parrot_capital.query('sentence_length < 513')\n",
    "parafrase_parrot_capital.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "## Citizen\n",
    "parafrase_t5_citizen[\"sentence_length\"]= parafrase_t5_citizen[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_citizen = parafrase_t5_citizen.query('sentence_length < 513')\n",
    "parafrase_t5_citizen.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_citizen[\"sentence_length\"]= parafrase_parrot_citizen[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_citizen = parafrase_parrot_citizen.query('sentence_length < 513')\n",
    "parafrase_parrot_citizen.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "## Works For\n",
    "parafrase_t5_worksfor[\"sentence_length\"]= parafrase_t5_worksfor[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_worksfor = parafrase_t5_worksfor.query('sentence_length < 513')\n",
    "parafrase_t5_worksfor.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_worksfor[\"sentence_length\"]= parafrase_parrot_worksfor[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_worksfor = parafrase_parrot_worksfor.query('sentence_length < 513')\n",
    "parafrase_parrot_worksfor.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "## Language\n",
    "parafrase_t5_language[\"sentence_length\"]= parafrase_t5_language[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_language = parafrase_t5_language.query('sentence_length < 513')\n",
    "parafrase_t5_language.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_language[\"sentence_length\"]= parafrase_parrot_language[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_language = parafrase_parrot_language.query('sentence_length < 513')\n",
    "parafrase_parrot_language.drop(columns=['sentence_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Language\n",
    "parafrase_t5_language[\"sentence_length\"]= parafrase_t5_language[\"masked_sentence\"].str.len()\n",
    "parafrase_t5_language = parafrase_t5_language.query('sentence_length < 513')\n",
    "parafrase_t5_language.drop(columns=['sentence_length'], inplace=True)\n",
    "\n",
    "parafrase_parrot_language[\"sentence_length\"]= parafrase_parrot_language[\"masked_sentence\"].str.len()\n",
    "parafrase_parrot_language = parafrase_parrot_language.query('sentence_length < 513')\n",
    "parafrase_parrot_language.drop(columns=['sentence_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parafrase_parrot_bornIn.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_bornIn.csv')\n",
    "parafrase_t5_bornIn.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_bornIn.csv')\n",
    "\n",
    "parafrase_parrot_diedIn.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_diedIn.csv')\n",
    "parafrase_t5_diedIn.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_diedIn.csv')\n",
    "\n",
    "parafrase_parrot_capital.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_capital.csv')\n",
    "parafrase_t5_capital.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_capital.csv')\n",
    "\n",
    "parafrase_parrot_citizen.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_citizen.csv')\n",
    "parafrase_t5_citizen.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_citizen.csv')\n",
    "\n",
    "parafrase_parrot_worksfor.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_worksfor.csv')\n",
    "parafrase_t5_worksfor.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_worksfor.csv')\n",
    "\n",
    "parafrase_parrot_language.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_language.csv')\n",
    "parafrase_t5_language.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parafrase_parrot_language.to_csv('/home/rafael/tese/code/data/novos_data/dados/parrot_language.csv')\n",
    "parafrase_t5_language.to_csv('/home/rafael/tese/code/data/novos_data/dados/t5_language.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt_results(df_column, masked_model,):\n",
    "    \"\"\"\n",
    "    Process the results of prompts using a masked language model.\n",
    "\n",
    "    Parameters:\n",
    "    df_column (list): A list of prompts to be processed.\n",
    "    masked_model: The masked language model used for processing.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries for each prompt, where each dictionary contains 'tokens' and 'score'.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for prompt in df_column:\n",
    "        if prompt is None:\n",
    "            outputs.append(nan)\n",
    "        elif prompt.find('[MASK]') == -1:\n",
    "            outputs.append(nan)\n",
    "        else:\n",
    "            for dictionary in masked_model(prompt):\n",
    "                outputs.append(dictionary['token_str'].strip().lower())\n",
    "            #outputs.append(\n",
    "            #    [dictionary['token_str'].strip().lower() for dictionary in masked_model(prompt)]\n",
    "            #    )\n",
    "    return outputs\n",
    "\n",
    "def process_prompt_results2(df_column, masked_model, with_socre=0):\n",
    "    \"\"\"\n",
    "    Process the results of prompts using a masked language model.\n",
    "\n",
    "    Parameters:\n",
    "    df_column (list): A list of prompts to be processed.\n",
    "    masked_model: The masked language model used for processing.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries for each prompt, where each dictionary contains 'tokens' and 'score'.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for prompt in df_column:\n",
    "        if prompt is None or prompt.find('[MASK]') == -1:\n",
    "                outputs.append(nan)\n",
    "        else:\n",
    "            outputs.append([{'token':item['token_str'].strip().lower(), \n",
    "                             'score':round(item['score'],3)} \\\n",
    "                                for item in masked_model(prompt)])      \n",
    "    return outputs\n",
    "\n",
    "def process_prompt_results_roberta2(df_column, masked_model, with_socre=0):\n",
    "    \"\"\"\n",
    "    Process the results of prompts using a masked language model.\n",
    "\n",
    "    Parameters:\n",
    "    df_column (list): A list of prompts to be processed.\n",
    "    masked_model: The masked language model used for processing.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries for each prompt, where each dictionary contains 'tokens' and 'score'.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for prompt in df_column:\n",
    "        if prompt is None or prompt.find('<mask>') == -1:\n",
    "                outputs.append(nan)\n",
    "        else:\n",
    "            outputs.append([{'token':item['token_str'].strip().lower(), \n",
    "                             'score':round(item['score'],3)} \\\n",
    "                                for item in masked_model(prompt)])      \n",
    "    return outputs\n",
    "\n",
    "def create_results_list(data, true_labels, num_iterations):\n",
    "    \"\"\"\n",
    "    Create a results list based on whether each corresponding true_label is present in the corresponding sublist of the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of sublists to search through\n",
    "    - true_labels: List of true_labels to check for in each sublist\n",
    "    - num_iterations: Number of iterations to consider for each sublist\n",
    "\n",
    "    Returns:\n",
    "    - results_list: List of 1s and 0s based on the presence of true_labels in the sublists\n",
    "\n",
    "    results_list = []\n",
    "    for sublist, true_label in zip(data, true_labels):\n",
    "        results_list.append(1 if true_label in sublist[:num_iterations] else 0)\n",
    "    \"\"\"\n",
    "    results_list = [1 if true_label in sublist[:num_iterations] else 0 for sublist, true_label in zip(data, true_labels)]\n",
    "    indices = [sublist.index(true_label) if true_label in sublist[:num_iterations] else None for sublist, true_label in zip(data, true_labels)]\n",
    "    return results_list, indices, round(average(results_list), 3)\n",
    "\n",
    "def get_first(seq):\n",
    "    if isinstance(seq, (tuple, list)):\n",
    "        return get_first(seq[0])\n",
    "    return seq\n",
    "\n",
    "def get_zero_list(seq):\n",
    "    return [get_first(i) for i in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bornIn = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_bornIn.csv')\n",
    "bornIn.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "capital = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_capital.csv')\n",
    "capital.drop(columns=['Unnamed: 0', 'filled_sentence'], inplace=True)\n",
    "diedIn = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_diedIn.csv')\n",
    "diedIn.drop(columns=['Unnamed: 0', 'filled_sentence'], inplace=True)\n",
    "worksfor = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_worksfor.csv')\n",
    "worksfor.drop(columns=['Unnamed: 0', 'filled_sentence'], inplace=True)\n",
    "citizen = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_citizen.csv')\n",
    "citizen.drop(columns=['Unnamed: 0', 'filled_sentence'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_language.csv')\n",
    "language.drop(columns=['Unnamed: 0', 'filled_sentence'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_substitution(text):\n",
    "    \"\"\"\n",
    "    Replace '[MASK]' with '<mask>' in the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text: Input text\n",
    "\n",
    "    Returns:\n",
    "    - Transformed text\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\[MASK\\]', '<mask>', text)\n",
    "\n",
    "def mask_substitution_use(df, columns):\n",
    "    for coluna in columns:\n",
    "        df[coluna] = df[coluna].apply(mask_substitution)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_substitution(text):\n",
    "    \"\"\"\n",
    "    Replace '[MASK]' with '<mask>' in the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text: Input text\n",
    "\n",
    "    Returns:\n",
    "    - Transformed text\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\<mask\\>', '[MASK]', text)\n",
    "\n",
    "def mask_substitution_use(df, columns):\n",
    "    for coluna in columns:\n",
    "        df[coluna] = df[coluna].apply(mask_substitution)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bornIn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Born In\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bornIn_roberta \u001b[38;5;241m=\u001b[39m mask_substitution_use(\u001b[43mbornIn\u001b[49m, bornIn\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m3\u001b[39m:])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Capital\u001b[39;00m\n\u001b[1;32m      5\u001b[0m capital_roberta \u001b[38;5;241m=\u001b[39m mask_substitution_use(capital, capital\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m3\u001b[39m:])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bornIn' is not defined"
     ]
    }
   ],
   "source": [
    "# Born In\n",
    "bornIn_roberta = mask_substitution_use(bornIn, bornIn.columns[3:])\n",
    "\n",
    "# Capital\n",
    "capital_roberta = mask_substitution_use(capital, capital.columns[3:])\n",
    "\n",
    "# Died In\n",
    "diedIn_roberta = mask_substitution_use(diedIn, diedIn.columns[3:])\n",
    "\n",
    "# Works For\n",
    "worksfor_roberta = mask_substitution_use(worksfor, worksfor.columns[3:])\n",
    "\n",
    "# Citizen\n",
    "citizen_roberta = mask_substitution_use(citizen, citizen.columns[3:])\n",
    "\n",
    "# Language\n",
    "language_roberta = mask_substitution_use(language, language.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language\n",
    "language_roberta = mask_substitution_use(language, language.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = mask_substitution_use(language, language.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Born in\n",
    "answer_filled_sentences_bornIn_t5 = bornIn['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_bornIn_parrot = parafrase_parrot_bornIn['obj_label'].str.lower().tolist()\n",
    "\n",
    "## Died In\n",
    "answer_filled_sentences_diedIn_t5 = diedIn['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_diedIn_parrot = parafrase_parrot_diedIn['obj_label'].str.lower().tolist()\n",
    "\n",
    "## The Capital is\n",
    "answer_filled_sentences_capital_t5 = capital['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_capital_parrot = parafrase_parrot_capital['obj_label'].str.lower().tolist()\n",
    "\n",
    "## Citizen\n",
    "answer_filled_sentences_citizen_t5 = citizen['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_citizen_parrot = parafrase_parrot_citizen['obj_label'].str.lower().tolist()\n",
    "\n",
    "## Works For\n",
    "answer_filled_sentences_worksfor_t5 = worksfor['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_worksfor_parrot = parafrase_parrot_worksfor['obj_label'].str.lower().tolist()\n",
    "\n",
    "## Language\n",
    "answer_filled_sentences_language_t5 = language['obj_label'].str.lower().tolist()\n",
    "\n",
    "#answer_filled_sentences_bornIn_withHelp = filled_sentences_bornIn_witHelp_1['obj_label'].str.lower().tolist()\n",
    "#answer_filled_sentences_bornIn_withHelp2 = filled_sentences_bornIn_witHelp_2['obj_label'].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Language\n",
    "answer_filled_sentences_language_t5 = language['obj_label'].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "unmasker_bertLarge = pipeline('fill-mask', model='bert-large-uncased', top_k = 10)#, top_k=10\n",
    "unmasker_robertaLarge = pipeline('fill-mask', model='FacebookAI/roberta-large', top_k = 10)#, top_k=10\n",
    "unmasker_electraLarge = pipeline('fill-mask', model='google/electra-large-generator', top_k = 10)#, top_k=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Born In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_bornIn_original= process_prompt_results2(bornIn['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_bornIn_t5_0= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_1= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_2= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_3= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_bornIn_t5_bert = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_bert_bornIn_original, \n",
    "                        't5_0': outputs_bert_bornIn_t5_0, \n",
    "                        't5_1': outputs_bert_bornIn_t5_1, \n",
    "                        't5_2': outputs_bert_bornIn_t5_2, \n",
    "                        't5_3': outputs_bert_bornIn_t5_3})\n",
    "outputs_len_bornIn_t5 = outputs_bornIn_t5_bert.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_bert.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_bornIn_original= process_prompt_results_roberta2(bornIn_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_bornIn_t5_0= process_prompt_results_roberta2(bornIn_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_1= process_prompt_results_roberta2(bornIn_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_2= process_prompt_results_roberta2(bornIn_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_3= process_prompt_results_roberta2(bornIn_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_bornIn_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_roberta_bornIn_original, \n",
    "                        't5_0': outputs_roberta_bornIn_t5_0, \n",
    "                        't5_1': outputs_roberta_bornIn_t5_1, \n",
    "                        't5_2': outputs_roberta_bornIn_t5_2, \n",
    "                        't5_3': outputs_roberta_bornIn_t5_3})\n",
    "outputs_len_bornIn_t5 = outputs_bornIn_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_bornIn_original= process_prompt_results2(bornIn['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_bornIn_t5_0= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_1= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_2= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_3= process_prompt_results2(bornIn['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_bornIn_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_electra_bornIn_original, \n",
    "                        't5_0': outputs_electra_bornIn_t5_0, \n",
    "                        't5_1': outputs_electra_bornIn_t5_1, \n",
    "                        't5_2': outputs_electra_bornIn_t5_2, \n",
    "                        't5_3': outputs_electra_bornIn_t5_3})\n",
    "outputs_len_bornIn_t5 = outputs_bornIn_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Died In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_diedIn_original= process_prompt_results2(diedIn['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_diedIn_t5_0= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_1= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_2= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_3= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_diedIn_t5 = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_bert_diedIn_original, \n",
    "                        't5_0': outputs_bert_diedIn_t5_0, \n",
    "                        't5_1': outputs_bert_diedIn_t5_1, \n",
    "                        't5_2': outputs_bert_diedIn_t5_2, \n",
    "                        't5_3': outputs_bert_diedIn_t5_3})\n",
    "outputs_len_diedIn_t5 = outputs_diedIn_t5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_diedIn_original= process_prompt_results_roberta2(diedIn_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_diedIn_t5_0= process_prompt_results_roberta2(diedIn_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_1= process_prompt_results_roberta2(diedIn_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_2= process_prompt_results_roberta2(diedIn_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_3= process_prompt_results_roberta2(diedIn_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_diedIn_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_roberta_diedIn_original, \n",
    "                        't5_0': outputs_roberta_diedIn_t5_0, \n",
    "                        't5_1': outputs_roberta_diedIn_t5_1, \n",
    "                        't5_2': outputs_roberta_diedIn_t5_2, \n",
    "                        't5_3': outputs_roberta_diedIn_t5_3})\n",
    "outputs_len_diedIn_t5 = outputs_diedIn_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_diedIn_original= process_prompt_results2(diedIn['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_diedIn_t5_0= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_1= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_2= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_3= process_prompt_results2(diedIn['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_diedIn_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_electra_diedIn_original, \n",
    "                        't5_0': outputs_electra_diedIn_t5_0, \n",
    "                        't5_1': outputs_electra_diedIn_t5_1, \n",
    "                        't5_2': outputs_electra_diedIn_t5_2, \n",
    "                        't5_3': outputs_electra_diedIn_t5_3})\n",
    "outputs_len_diedIn_t5 = outputs_diedIn_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_capital_original= process_prompt_results2(capital['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_capital_t5_0= process_prompt_results2(capital['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_1= process_prompt_results2(capital['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_2= process_prompt_results2(capital['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_3= process_prompt_results2(capital['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_capital_t5_bert = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_bert_capital_original, \n",
    "                        't5_0': outputs_bert_capital_t5_0, \n",
    "                        't5_1': outputs_bert_capital_t5_1, \n",
    "                        't5_2': outputs_bert_capital_t5_2, \n",
    "                        't5_3': outputs_bert_capital_t5_3})\n",
    "outputs_len_capital_t5 = outputs_capital_t5_bert.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_bert.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_capital_original= process_prompt_results_roberta2(capital_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_capital_t5_0= process_prompt_results_roberta2(capital_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_1= process_prompt_results_roberta2(capital_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_2= process_prompt_results_roberta2(capital_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_3= process_prompt_results_roberta2(capital_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_capital_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_roberta_capital_original, \n",
    "                        't5_0': outputs_roberta_capital_t5_0, \n",
    "                        't5_1': outputs_roberta_capital_t5_1, \n",
    "                        't5_2': outputs_roberta_capital_t5_2, \n",
    "                        't5_3': outputs_roberta_capital_t5_3})\n",
    "outputs_len_capital_t5 = outputs_capital_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_capital_original= process_prompt_results2(capital['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_capital_t5_0= process_prompt_results2(capital['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_1= process_prompt_results2(capital['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_2= process_prompt_results2(capital['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_3= process_prompt_results2(capital['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_capital_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_electra_capital_original, \n",
    "                        't5_0': outputs_electra_capital_t5_0, \n",
    "                        't5_1': outputs_electra_capital_t5_1, \n",
    "                        't5_2': outputs_electra_capital_t5_2, \n",
    "                        't5_3': outputs_electra_capital_t5_3})\n",
    "outputs_len_capital_t5 = outputs_capital_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_worksfor_original= process_prompt_results2(worksfor['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_worksfor_t5_0= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_1= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_2= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_3= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_worksfor_t5_bert = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_bert_worksfor_original, \n",
    "                        't5_0': outputs_bert_worksfor_t5_0, \n",
    "                        't5_1': outputs_bert_worksfor_t5_1, \n",
    "                        't5_2': outputs_bert_worksfor_t5_2, \n",
    "                        't5_3': outputs_bert_worksfor_t5_3})\n",
    "outputs_len_worksfor_t5 = outputs_worksfor_t5_bert.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_bert.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_worksfor_original= process_prompt_results_roberta2(worksfor_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_worksfor_t5_0= process_prompt_results_roberta2(worksfor_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_1= process_prompt_results_roberta2(worksfor_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_2= process_prompt_results_roberta2(worksfor_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_3= process_prompt_results_roberta2(worksfor_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_worksfor_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_roberta_worksfor_original, \n",
    "                        't5_0': outputs_roberta_worksfor_t5_0, \n",
    "                        't5_1': outputs_roberta_worksfor_t5_1, \n",
    "                        't5_2': outputs_roberta_worksfor_t5_2, \n",
    "                        't5_3': outputs_roberta_worksfor_t5_3})\n",
    "outputs_len_worksfor_t5 = outputs_worksfor_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_worksfor_original= process_prompt_results2(worksfor['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_worksfor_t5_0= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_1= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_2= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_3= process_prompt_results2(worksfor['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_worksfor_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_electra_worksfor_original, \n",
    "                        't5_0': outputs_electra_worksfor_t5_0, \n",
    "                        't5_1': outputs_electra_worksfor_t5_1, \n",
    "                        't5_2': outputs_electra_worksfor_t5_2, \n",
    "                        't5_3': outputs_electra_worksfor_t5_3})\n",
    "outputs_len_worksfor_t5 = outputs_worksfor_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_citizen_original= process_prompt_results2(citizen['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_citizen_t5_0= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_1= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_2= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_3= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_citizen_t5_bert = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_bert_citizen_original, \n",
    "                        't5_0': outputs_bert_citizen_t5_0, \n",
    "                        't5_1': outputs_bert_citizen_t5_1, \n",
    "                        't5_2': outputs_bert_citizen_t5_2, \n",
    "                        't5_3': outputs_bert_citizen_t5_3})\n",
    "outputs_len_citizen_t5 = outputs_citizen_t5_bert.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_bert.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_citizen_original= process_prompt_results_roberta2(citizen_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_citizen_t5_0= process_prompt_results_roberta2(citizen_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_1= process_prompt_results_roberta2(citizen_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_2= process_prompt_results_roberta2(citizen_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_3= process_prompt_results_roberta2(citizen_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_citizen_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_roberta_citizen_original, \n",
    "                        't5_0': outputs_roberta_citizen_t5_0, \n",
    "                        't5_1': outputs_roberta_citizen_t5_1, \n",
    "                        't5_2': outputs_roberta_citizen_t5_2, \n",
    "                        't5_3': outputs_roberta_citizen_t5_3})\n",
    "outputs_len_citizen_t5 = outputs_citizen_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_citizen_original= process_prompt_results2(citizen['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_citizen_t5_0= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_1= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_2= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_3= process_prompt_results2(citizen['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_citizen_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_electra_citizen_original, \n",
    "                        't5_0': outputs_electra_citizen_t5_0, \n",
    "                        't5_1': outputs_electra_citizen_t5_1, \n",
    "                        't5_2': outputs_electra_citizen_t5_2, \n",
    "                        't5_3': outputs_electra_citizen_t5_3})\n",
    "outputs_len_citizen_t5 = outputs_citizen_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_language_original= process_prompt_results2(language['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_language_t5_0= process_prompt_results2(language['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_1= process_prompt_results2(language['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_2= process_prompt_results2(language['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_3= process_prompt_results2(language['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_language_t5_bert = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_bert_language_original, \n",
    "                        't5_0': outputs_bert_language_t5_0, \n",
    "                        't5_1': outputs_bert_language_t5_1, \n",
    "                        't5_2': outputs_bert_language_t5_2, \n",
    "                        't5_3': outputs_bert_language_t5_3})\n",
    "outputs_len_language_t5 = outputs_language_t5_bert.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_bert.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_language_original= process_prompt_results_roberta2(language_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_language_t5_0= process_prompt_results_roberta2(language_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_1= process_prompt_results_roberta2(language_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_2= process_prompt_results_roberta2(language_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_3= process_prompt_results_roberta2(language_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_language_t5_roberta = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_roberta_language_original, \n",
    "                        't5_0': outputs_roberta_language_t5_0, \n",
    "                        't5_1': outputs_roberta_language_t5_1, \n",
    "                        't5_2': outputs_roberta_language_t5_2, \n",
    "                        't5_3': outputs_roberta_language_t5_3})\n",
    "outputs_len_language_t5 = outputs_language_t5_roberta.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_roberta.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_roberta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_language_original= process_prompt_results2(language['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_language_t5_0= process_prompt_results2(language['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_1= process_prompt_results2(language['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_2= process_prompt_results2(language['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_3= process_prompt_results2(language['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_language_t5_electra = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_electra_language_original, \n",
    "                        't5_0': outputs_electra_language_t5_0, \n",
    "                        't5_1': outputs_electra_language_t5_1, \n",
    "                        't5_2': outputs_electra_language_t5_2, \n",
    "                        't5_3': outputs_electra_language_t5_3})\n",
    "outputs_len_language_t5 = outputs_language_t5_electra.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_electra.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_electra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One and Few Shoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substituir_x(row):\n",
    "    return row['template'].replace('[X]', row['sub_label'])\n",
    "\n",
    "def substituir_y(row):\n",
    "    return row['triple_NL'].replace('[Y]', row['obj_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Born In\n",
    "bornIn_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_bornIn.csv')\n",
    "bornIn_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_bornIn = bornIn_prompt[bornIn_prompt.columns[0:3]]\n",
    "\n",
    "# Died In\n",
    "diedIn_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_diedIn.csv')\n",
    "diedIn_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_diedIn = diedIn_prompt[diedIn_prompt.columns[0:3]]\n",
    "\n",
    "# Capital\n",
    "capital_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_capital.csv')\n",
    "capital_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_capital = capital_prompt[capital_prompt.columns[0:3]]\n",
    "\n",
    "# Works For\n",
    "worksfor_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_worksfor.csv')\n",
    "worksfor_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_worksfor = worksfor_prompt[worksfor_prompt.columns[0:3]]\n",
    "\n",
    "# Citizen\n",
    "citizen_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_citizen.csv')\n",
    "citizen_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_citizen = citizen_prompt[citizen_prompt.columns[0:3]]\n",
    "\n",
    "# Language\n",
    "language_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_language.csv')\n",
    "language_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_language = language_prompt[language_prompt.columns[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language\n",
    "language_prompt = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/t5_language.csv')\n",
    "language_prompt.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "triple_language = language_prompt[language_prompt.columns[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Born In\n",
    "triple_bornIn.loc[:, 'triple_NL'] = triple_bornIn.apply(substituir_x, axis=1)\n",
    "triple_bornIn.loc[:, 'triple_NL'] = triple_bornIn.apply(substituir_y, axis=1)\n",
    "\n",
    "# Died In\n",
    "triple_diedIn.loc[:, 'triple_NL'] = triple_diedIn.apply(substituir_x, axis=1)\n",
    "triple_diedIn.loc[:, 'triple_NL'] = triple_diedIn.apply(substituir_y, axis=1)\n",
    "\n",
    "# Capital\n",
    "triple_capital.loc[:, 'triple_NL'] = triple_capital.apply(substituir_x, axis=1)\n",
    "triple_capital.loc[:, 'triple_NL'] = triple_capital.apply(substituir_y, axis=1)\n",
    "\n",
    "# Works For\n",
    "triple_worksfor.loc[:, 'triple_NL'] = triple_worksfor.apply(substituir_x, axis=1)\n",
    "triple_worksfor.loc[:, 'triple_NL'] = triple_worksfor.apply(substituir_y, axis=1)\n",
    "\n",
    "# Citizen\n",
    "triple_citizen.loc[:, 'triple_NL'] = triple_citizen.apply(substituir_x, axis=1)\n",
    "triple_citizen.loc[:, 'triple_NL'] = triple_citizen.apply(substituir_y, axis=1)\n",
    "\n",
    "# Language\n",
    "triple_language.loc[:, 'triple_NL'] = triple_language.apply(substituir_x, axis=1)\n",
    "triple_language.loc[:, 'triple_NL'] = triple_language.apply(substituir_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language\n",
    "triple_language.loc[:, 'triple_NL'] = triple_language.apply(substituir_x, axis=1)\n",
    "triple_language.loc[:, 'triple_NL'] = triple_language.apply(substituir_y, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Born In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_bornIn['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = bornIn_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_bornIn_witHelp_1 = bornIn_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(bornIn_prompt.shape[0])]\n",
    "    filled_sentences_bornIn_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, bornIn_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_bornIn_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = bornIn_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_bornIn_witHelp_3 = bornIn_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(bornIn_prompt.shape[0])]\n",
    "    filled_sentences_bornIn_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, bornIn_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_bornIn_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Died In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_diedIn['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = diedIn_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_diedIn_witHelp_1 = diedIn_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(diedIn_prompt.shape[0])]\n",
    "    filled_sentences_diedIn_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, diedIn_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_diedIn_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = diedIn_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_diedIn_witHelp_3 = diedIn_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(diedIn_prompt.shape[0])]\n",
    "    filled_sentences_diedIn_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, diedIn_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_diedIn_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_capital['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = capital_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_capital_witHelp_1 = capital_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(capital_prompt.shape[0])]\n",
    "    filled_sentences_capital_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, capital_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_capital_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = capital_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_capital_witHelp_3 = capital_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(capital_prompt.shape[0])]\n",
    "    filled_sentences_capital_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, capital_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_capital_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_worksfor['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = worksfor_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_worksfor_witHelp_1 = worksfor_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(worksfor_prompt.shape[0])]\n",
    "    filled_sentences_worksfor_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, worksfor_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_worksfor_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = worksfor_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_worksfor_witHelp_3 = worksfor_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(worksfor_prompt.shape[0])]\n",
    "    filled_sentences_worksfor_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, worksfor_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_worksfor_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_citizen['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = citizen_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_citizen_witHelp_1 = citizen_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(citizen_prompt.shape[0])]\n",
    "    filled_sentences_citizen_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, citizen_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_citizen_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = citizen_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_citizen_witHelp_3 = citizen_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(citizen_prompt.shape[0])]\n",
    "    filled_sentences_citizen_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, citizen_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_citizen_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "# Selecionar aleatoriamente três itens da coluna 'text'\n",
    "itens_selecionados = random.sample(triple_language['triple_NL'].tolist(), 10)\n",
    "\n",
    "# Gerar todas as combinações possíveis das frases selecionadas sem repeti-las\n",
    "combinacoes = list(itertools.combinations(itens_selecionados, 3))\n",
    "combinacoes = [list(tupla) for tupla in combinacoes]\n",
    "\n",
    "# Lista para armazenar as frases unidas\n",
    "frases_unidas = []\n",
    "\n",
    "# Iterar sobre cada lista interna\n",
    "for lista in combinacoes:\n",
    "    # Unir as frases na lista interna\n",
    "    frase_unida = ' '.join(lista)\n",
    "    # Adicionar a frase unida à lista de frases unidas\n",
    "    frases_unidas.append(frase_unida)\n",
    "\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = language_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_language_witHelp_1 = language_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(itens_selecionados) for _ in range(language_prompt.shape[0])]\n",
    "    filled_sentences_language_witHelp_1[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, language_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_language_witHelp_1)\n",
    "\n",
    "random.seed(42)\n",
    "# Lista das colunas que você deseja concatenar\n",
    "colunas_para_concatenar = language_prompt.columns[3:]\n",
    "\n",
    "# Copiando o DataFrame para evitar modificar o original\n",
    "filled_sentences_language_witHelp_3 = language_prompt[['sub_label', 'template', 'obj_label',]].copy()\n",
    "\n",
    "# Concatenando as colunas selecionadas e criando uma nova coluna no DataFrame para armazenar os resultados\n",
    "for coluna in colunas_para_concatenar:\n",
    "    # Selecionar aleatoriamente uma frase da lista itens_selecionados para cada linha\n",
    "    frases_aleatorias = [random.choice(frases_unidas) for _ in range(language_prompt.shape[0])]\n",
    "    filled_sentences_language_witHelp_3[coluna] = [frase + valor for frase, valor in zip(frases_aleatorias, language_prompt[coluna])]\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "#display(filled_sentences_language_witHelp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_substitution(text):\n",
    "    \"\"\"\n",
    "    Replace '[MASK]' with '<mask>' in the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text: Input text\n",
    "\n",
    "    Returns:\n",
    "    - Transformed text\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\[MASK\\]', '<mask>', text)\n",
    "\n",
    "def mask_substitution_use(df, columns):\n",
    "    for coluna in columns:\n",
    "        df[coluna] = df[coluna].apply(mask_substitution)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Born In\n",
    "filled_sentences_bornIn_witHelp_1_roberta = mask_substitution_use(filled_sentences_bornIn_witHelp_1, filled_sentences_bornIn_witHelp_1.columns[3:])\n",
    "filled_sentences_bornIn_witHelp_2_roberta = mask_substitution_use(filled_sentences_bornIn_witHelp_3, filled_sentences_bornIn_witHelp_3.columns[3:])\n",
    "\n",
    "# Capital\n",
    "filled_sentences_capital_witHelp_1_roberta = mask_substitution_use(filled_sentences_capital_witHelp_1, filled_sentences_capital_witHelp_1.columns[3:])\n",
    "filled_sentences_capital_witHelp_2_roberta = mask_substitution_use(filled_sentences_capital_witHelp_3, filled_sentences_capital_witHelp_3.columns[3:])\n",
    "\n",
    "# Died In\n",
    "filled_sentences_diedIn_witHelp_1_roberta = mask_substitution_use(filled_sentences_diedIn_witHelp_1, filled_sentences_diedIn_witHelp_1.columns[3:])\n",
    "filled_sentences_diedIn_witHelp_2_roberta = mask_substitution_use(filled_sentences_diedIn_witHelp_3, filled_sentences_diedIn_witHelp_3.columns[3:])\n",
    "\n",
    "# Works For\n",
    "filled_sentences_worksfor_witHelp_1_roberta = mask_substitution_use(filled_sentences_worksfor_witHelp_1, filled_sentences_worksfor_witHelp_1.columns[3:])\n",
    "filled_sentences_worksfor_witHelp_2_roberta = mask_substitution_use(filled_sentences_worksfor_witHelp_3, filled_sentences_worksfor_witHelp_3.columns[3:])\n",
    "\n",
    "# Citizen\n",
    "filled_sentences_citizen_witHelp_1_roberta = mask_substitution_use(filled_sentences_citizen_witHelp_1, filled_sentences_citizen_witHelp_1.columns[3:])\n",
    "filled_sentences_citizen_witHelp_2_roberta = mask_substitution_use(filled_sentences_citizen_witHelp_3, filled_sentences_citizen_witHelp_3.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language\n",
    "filled_sentences_language_witHelp_1_roberta = mask_substitution_use(filled_sentences_language_witHelp_1, filled_sentences_language_witHelp_1.columns[3:])\n",
    "filled_sentences_language_witHelp_2_roberta = mask_substitution_use(filled_sentences_language_witHelp_3, filled_sentences_language_witHelp_3.columns[3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilzando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Shoot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Born In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_bornIn_original_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_bornIn_t5_0_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_1_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_2_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_3_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_bornIn_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_bert_bornIn_original_one_shoot, \n",
    "                        't5_0': outputs_bert_bornIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_bornIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_bornIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_bornIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_bornIn_original_one_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_bornIn_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_bornIn_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_roberta_bornIn_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_bornIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_bornIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_bornIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_bornIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_bornIn_original_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_bornIn_t5_0_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_1_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_2_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_3_one_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_bornIn_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_electra_bornIn_original_one_shoot, \n",
    "                        't5_0': outputs_electra_bornIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_bornIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_bornIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_bornIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Died In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_diedIn_original_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_diedIn_t5_0_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_1_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_2_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_3_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_diedIn_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_bert_diedIn_original_one_shoot, \n",
    "                        't5_0': outputs_bert_diedIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_diedIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_diedIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_diedIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_diedIn_original_one_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_diedIn_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_diedIn_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_roberta_diedIn_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_diedIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_diedIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_diedIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_diedIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_diedIn_original_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_diedIn_t5_0_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_1_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_2_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_3_one_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_diedIn_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_electra_diedIn_original_one_shoot, \n",
    "                        't5_0': outputs_electra_diedIn_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_diedIn_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_diedIn_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_diedIn_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_capital_original_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_capital_t5_0_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_1_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_2_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_3_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_capital_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_bert_capital_original_one_shoot, \n",
    "                        't5_0': outputs_bert_capital_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_capital_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_capital_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_capital_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_capital_original_one_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_capital_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_capital_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_roberta_capital_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_capital_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_capital_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_capital_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_capital_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_capital_original_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_capital_t5_0_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_1_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_2_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_3_one_shoot= process_prompt_results2(filled_sentences_capital_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_capital_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_electra_capital_original_one_shoot, \n",
    "                        't5_0': outputs_electra_capital_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_capital_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_capital_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_capital_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_worksfor_original_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_worksfor_t5_0_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_1_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_2_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_3_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_worksfor_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_bert_worksfor_original_one_shoot, \n",
    "                        't5_0': outputs_bert_worksfor_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_worksfor_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_worksfor_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_worksfor_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_worksfor_original_one_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_worksfor_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_worksfor_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_roberta_worksfor_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_worksfor_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_worksfor_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_worksfor_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_worksfor_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_worksfor_original_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_worksfor_t5_0_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_1_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_2_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_3_one_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_worksfor_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_electra_worksfor_original_one_shoot, \n",
    "                        't5_0': outputs_electra_worksfor_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_worksfor_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_worksfor_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_worksfor_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_citizen_original_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_citizen_t5_0_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_1_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_2_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_3_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_citizen_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_bert_citizen_original_one_shoot, \n",
    "                        't5_0': outputs_bert_citizen_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_citizen_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_citizen_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_citizen_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_citizen_original_one_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_citizen_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_citizen_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_roberta_citizen_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_citizen_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_citizen_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_citizen_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_citizen_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_citizen_original_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_citizen_t5_0_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_1_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_2_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_3_one_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_citizen_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_electra_citizen_original_one_shoot, \n",
    "                        't5_0': outputs_electra_citizen_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_citizen_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_citizen_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_citizen_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_language_original_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_language_t5_0_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_1_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_2_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_3_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_language_t5_bert_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_bert_language_original_one_shoot, \n",
    "                        't5_0': outputs_bert_language_t5_0_one_shoot, \n",
    "                        't5_1': outputs_bert_language_t5_1_one_shoot, \n",
    "                        't5_2': outputs_bert_language_t5_2_one_shoot, \n",
    "                        't5_3': outputs_bert_language_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_bert_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_bert_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_language_original_one_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_1_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_language_t5_0_one_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_1_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_1_one_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_1_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_2_one_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_1_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_3_one_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_1_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_language_t5_roberta_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_roberta_language_original_one_shoot, \n",
    "                        't5_0': outputs_roberta_language_t5_0_one_shoot, \n",
    "                        't5_1': outputs_roberta_language_t5_1_one_shoot, \n",
    "                        't5_2': outputs_roberta_language_t5_2_one_shoot, \n",
    "                        't5_3': outputs_roberta_language_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_roberta_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_roberta_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_language_original_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_language_t5_0_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_1_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_2_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_3_one_shoot= process_prompt_results2(filled_sentences_language_witHelp_1['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_language_t5_electra_one_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_electra_language_original_one_shoot, \n",
    "                        't5_0': outputs_electra_language_t5_0_one_shoot, \n",
    "                        't5_1': outputs_electra_language_t5_1_one_shoot, \n",
    "                        't5_2': outputs_electra_language_t5_2_one_shoot, \n",
    "                        't5_3': outputs_electra_language_t5_3_one_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_electra_one_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_electra_one_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shoot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Born In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_bornIn_original_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_bornIn_t5_0_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_1_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_2_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_bornIn_t5_3_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_bornIn_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_bert_bornIn_original_few_shoot, \n",
    "                        't5_0': outputs_bert_bornIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_bornIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_bornIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_bornIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_bornIn_original_few_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_bornIn_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_bornIn_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_bornIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_bornIn_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_roberta_bornIn_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_bornIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_bornIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_bornIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_bornIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_bornIn_original_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_bornIn_t5_0_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_1_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_2_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_bornIn_t5_3_few_shoot= process_prompt_results2(filled_sentences_bornIn_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_bornIn_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_bornIn_t5,\n",
    "                        'original': outputs_electra_bornIn_original_few_shoot, \n",
    "                        't5_0': outputs_electra_bornIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_bornIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_bornIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_bornIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bornIn_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_bornIn_t5_electra_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Died In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_diedIn_original_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_diedIn_t5_0_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_1_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_2_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_diedIn_t5_3_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_diedIn_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_bert_diedIn_original_few_shoot, \n",
    "                        't5_0': outputs_bert_diedIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_diedIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_diedIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_diedIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_diedIn_original_few_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_diedIn_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_diedIn_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_diedIn_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_diedIn_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_roberta_diedIn_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_diedIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_diedIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_diedIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_diedIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_diedIn_original_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_diedIn_t5_0_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_1_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_2_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_diedIn_t5_3_few_shoot= process_prompt_results2(filled_sentences_diedIn_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_diedIn_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_diedIn_t5,\n",
    "                        'original': outputs_electra_diedIn_original_few_shoot, \n",
    "                        't5_0': outputs_electra_diedIn_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_diedIn_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_diedIn_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_diedIn_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_diedIn_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_diedIn_t5_electra_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_capital_original_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_capital_t5_0_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_1_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_2_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_capital_t5_3_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_capital_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_bert_capital_original_few_shoot, \n",
    "                        't5_0': outputs_bert_capital_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_capital_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_capital_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_capital_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_capital_original_few_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_capital_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_capital_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_capital_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_capital_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_roberta_capital_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_capital_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_capital_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_capital_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_capital_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_capital_original_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_capital_t5_0_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_1_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_2_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_capital_t5_3_few_shoot= process_prompt_results2(filled_sentences_capital_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_capital_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_capital_t5,\n",
    "                        'original': outputs_electra_capital_original_few_shoot, \n",
    "                        't5_0': outputs_electra_capital_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_capital_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_capital_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_capital_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_capital_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_capital_t5_electra_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Works for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_worksfor_original_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_worksfor_t5_0_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_1_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_2_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_worksfor_t5_3_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_worksfor_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_bert_worksfor_original_few_shoot, \n",
    "                        't5_0': outputs_bert_worksfor_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_worksfor_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_worksfor_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_worksfor_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_worksfor_original_few_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_worksfor_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_worksfor_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_worksfor_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_worksfor_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_roberta_worksfor_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_worksfor_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_worksfor_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_worksfor_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_worksfor_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_worksfor_original_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_worksfor_t5_0_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_1_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_2_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_worksfor_t5_3_few_shoot= process_prompt_results2(filled_sentences_worksfor_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_worksfor_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_worksfor_t5,\n",
    "                        'original': outputs_electra_worksfor_original_few_shoot, \n",
    "                        't5_0': outputs_electra_worksfor_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_worksfor_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_worksfor_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_worksfor_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_worksfor_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_worksfor_t5_electra_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citizen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_citizen_original_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_citizen_t5_0_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_1_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_2_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_citizen_t5_3_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_citizen_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_bert_citizen_original_few_shoot, \n",
    "                        't5_0': outputs_bert_citizen_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_citizen_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_citizen_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_citizen_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_citizen_original_few_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_citizen_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_citizen_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_citizen_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_citizen_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_roberta_citizen_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_citizen_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_citizen_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_citizen_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_citizen_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_citizen_original_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_citizen_t5_0_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_1_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_2_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_citizen_t5_3_few_shoot= process_prompt_results2(filled_sentences_citizen_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_citizen_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_citizen_t5,\n",
    "                        'original': outputs_electra_citizen_original_few_shoot, \n",
    "                        't5_0': outputs_electra_citizen_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_citizen_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_citizen_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_citizen_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_citizen_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_citizen_t5_electra_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_bert_language_original_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_bertLarge)\n",
    "\n",
    "outputs_bert_language_t5_0_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_1_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_2_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_bertLarge)\n",
    "outputs_bert_language_t5_3_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_bertLarge)\n",
    "\n",
    "outputs_language_t5_bert_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_bert_language_original_few_shoot, \n",
    "                        't5_0': outputs_bert_language_t5_0_few_shoot, \n",
    "                        't5_1': outputs_bert_language_t5_1_few_shoot, \n",
    "                        't5_2': outputs_bert_language_t5_2_few_shoot, \n",
    "                        't5_3': outputs_bert_language_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_bert_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_bert_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_roberta_language_original_few_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_2_roberta['masked_sentence'], \n",
    "                                                             unmasker_robertaLarge)\n",
    "\n",
    "outputs_roberta_language_t5_0_few_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_2_roberta['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_1_few_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_2_roberta['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_2_few_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_2_roberta['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "outputs_roberta_language_t5_3_few_shoot= process_prompt_results_roberta2(filled_sentences_language_witHelp_2_roberta['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_robertaLarge)\n",
    "\n",
    "outputs_language_t5_roberta_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_roberta_language_original_few_shoot, \n",
    "                        't5_0': outputs_roberta_language_t5_0_few_shoot, \n",
    "                        't5_1': outputs_roberta_language_t5_1_few_shoot, \n",
    "                        't5_2': outputs_roberta_language_t5_2_few_shoot, \n",
    "                        't5_3': outputs_roberta_language_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_roberta_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_roberta_few_shoot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_electra_language_original_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['masked_sentence'], \n",
    "                                                             unmasker_electraLarge)\n",
    "\n",
    "outputs_electra_language_t5_0_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_0'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_1_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_1'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_2_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_2'], \n",
    "                                                         unmasker_electraLarge)\n",
    "outputs_electra_language_t5_3_few_shoot= process_prompt_results2(filled_sentences_language_witHelp_3['T5_paraphrased_filled_sentence_3'], \n",
    "                                                         unmasker_electraLarge)\n",
    "\n",
    "outputs_language_t5_electra_few_shoot = pd.DataFrame({'answers': answer_filled_sentences_language_t5,\n",
    "                        'original': outputs_electra_language_original_few_shoot, \n",
    "                        't5_0': outputs_electra_language_t5_0_few_shoot, \n",
    "                        't5_1': outputs_electra_language_t5_1_few_shoot, \n",
    "                        't5_2': outputs_electra_language_t5_2_few_shoot, \n",
    "                        't5_3': outputs_electra_language_t5_3_few_shoot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_language_t5_electra_few_shoot.to_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/outputs_language_t5_electra_few_shoot.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
