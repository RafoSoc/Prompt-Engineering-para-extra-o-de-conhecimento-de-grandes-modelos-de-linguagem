{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEJrx6chRkTD",
        "outputId": "534e5dd1-6d45-454b-d8a0-ca6f995993c9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "from numpy import average, round"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available: True\n",
            "How many is available: 1\n",
            "Which is available: 0\n",
            "Device name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
            "Device capability: (8, 9)\n",
            "Device memory: 7.75 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"Available: {torch.cuda.is_available()}\")\n",
        "print(f\"How many is available: {torch.cuda.device_count()}\")\n",
        "print(f\"Which is available: {torch.cuda.current_device()}\")\n",
        "print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
        "print(f\"Device memory: {round(torch.cuda.get_device_properties(0).total_memory/1024**3,2)} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T7vvItRgRoZJ"
      },
      "outputs": [],
      "source": [
        "def create_results_list(data, true_labels, num_iterations):\n",
        "    \"\"\"\n",
        "    Create a results list based on whether each corresponding true_label is present in the corresponding sublist of the data.\n",
        "\n",
        "    Parameters:\n",
        "    - data: List of sublists to search through\n",
        "    - true_labels: List of true_labels to check for in each sublist\n",
        "    - num_iterations: Number of iterations to consider for each sublist\n",
        "\n",
        "    Returns:\n",
        "    - results_list: List of 1s and 0s based on the presence of true_labels in the sublists\n",
        "\n",
        "    results_list = []\n",
        "    for sublist, true_label in zip(data, true_labels):\n",
        "        results_list.append(1 if true_label in sublist[:num_iterations] else 0)\n",
        "    \"\"\"\n",
        "    results_list = [1 if true_label in sublist[:num_iterations] else 0 for sublist, true_label in zip(data, true_labels)]\n",
        "    indices = [sublist.index(true_label) if true_label in sublist[:num_iterations] else None for sublist, true_label in zip(data, true_labels)]\n",
        "    return results_list, indices, round(average(results_list), 3)\n",
        "\n",
        "def ranking(row, columns):\n",
        "    \"\"\"\n",
        "    Função que realiza o ranqueamento dos tokens em uma linha de dados, com base nas colunas fornecidas.\n",
        "\n",
        "    Parâmetros:\n",
        "    - row: dict - Dicionário contendo as informações da linha de dados.\n",
        "    - columns: list - Lista das colunas que contêm os tokens a serem ranqueados.\n",
        "\n",
        "    Retorna:\n",
        "    - list - Lista de dicionários contendo os tokens ranqueados, ordenados pelo score em ordem decrescente.\n",
        "    \"\"\"\n",
        "\n",
        "    tokens_combinados = {}\n",
        "    for col in columns:\n",
        "        for token_info in row[col]:\n",
        "            token = token_info['token']\n",
        "            score = token_info['score']\n",
        "            if token in tokens_combinados:\n",
        "                tokens_combinados[token]['score'] += score\n",
        "            else:\n",
        "                tokens_combinados[token] = {'token': token, 'score': score}\n",
        "    return sorted(list(tokens_combinados.values()), key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "def ranking_dataframe(df, columns):\n",
        "    \"\"\"\n",
        "    Retorna uma lista de tokens finais para cada linha do dataframe, com base no ranking calculado usando as colunas fornecidas.\n",
        "\n",
        "    Parâmetros:\n",
        "    - df: DataFrame - O dataframe de entrada contendo os dados.\n",
        "    - columns: list - Uma lista de colunas usadas para calcular o ranking.\n",
        "\n",
        "    Retorno:\n",
        "    - tokens_finais: list - Uma lista de tokens finais para cada linha do dataframe.\n",
        "    \"\"\"\n",
        "    tokens_finais = [ranking(row, columns) for _, row in df.iterrows()]\n",
        "    return tokens_finais\n",
        "\n",
        "\n",
        "# Função para converter uma string para uma lista\n",
        "def str_to_list(x):\n",
        "    \"\"\"\n",
        "    Converte uma string em uma lista.\n",
        "\n",
        "    Parâmetros:\n",
        "    x (str): A string a ser convertida.\n",
        "\n",
        "    Retorna:\n",
        "    list: A lista resultante da conversão da string.\n",
        "          Se a conversão falhar, retorna a string original.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return ast.literal_eval(x)\n",
        "    except (SyntaxError, ValueError):\n",
        "        return x\n",
        "\n",
        "# Função para extrair os tokens\n",
        "def extrair_tokens(lista_dicts):\n",
        "    \"\"\"\n",
        "    Função que extrai os tokens de uma lista de dicionários.\n",
        "\n",
        "    Parâmetros:\n",
        "    - lista_dicts (list): Uma lista de dicionários contendo a chave 'token'.\n",
        "\n",
        "    Retorna:\n",
        "    - Uma lista contendo os valores da chave 'token' de cada dicionário.\n",
        "\n",
        "    Exemplo:\n",
        "    >>> lista = [{'token': 'Olá'}, {'token': 'mundo'}, {'token': '!'}]\n",
        "    >>> extrair_tokens(lista)\n",
        "    ['Olá', 'mundo', '!']\n",
        "    \"\"\"\n",
        "    return [item['token'] for item in lista_dicts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5bz6HjdCWtJ9"
      },
      "outputs": [],
      "source": [
        "def filtrar_GPE(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'GPE':  # GPE representa entidades nomeadas de países, cidades, estados.\n",
        "                nomes_lugares.append({'token': token, 'score': score})\n",
        "                break\n",
        "\n",
        "    return nomes_lugares\n",
        "\n",
        "def filtrar_ORG(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'ORG':  # ORG representa entidades nomeadas de empresas, agências, instituições, etc.\n",
        "                nomes_lugares.append({'token': token, 'score': score})\n",
        "                break\n",
        "\n",
        "    return nomes_lugares\n",
        "\n",
        "def filtrar_NORP(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'NORP':  # GPE representa entidades nomeadas de nacionalidades ou grupos religiosos ou políticos.\n",
        "                nomes_lugares.append({'token': token, 'score': score})\n",
        "                break\n",
        "\n",
        "    return nomes_lugares\n",
        "\n",
        "def zerando_nao_GPE(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        token_score = score if any(ent.label_ == 'GPE' for ent in doc.ents) else 0.0\n",
        "        nomes_lugares.append({'token': token, 'score': token_score})\n",
        "\n",
        "    # Ordenar a lista pelo score\n",
        "    nomes_lugares.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    return nomes_lugares\n",
        "\n",
        "def zerando_nao_ORG(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        token_score = score if any(ent.label_ == 'ORG' for ent in doc.ents) else 0.0\n",
        "        nomes_lugares.append({'token': token, 'score': token_score})\n",
        "\n",
        "    # Ordenar a lista pelo score\n",
        "    nomes_lugares.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    return nomes_lugares\n",
        "\n",
        "def zerando_nao_NORP(lista):\n",
        "    nomes_lugares = []\n",
        "\n",
        "    for item in lista:\n",
        "        token = item['token']\n",
        "        score = item['score']\n",
        "        doc = nlp(token)\n",
        "        token_score = score if any(ent.label_ == 'NORP' for ent in doc.ents) else 0.0\n",
        "        nomes_lugares.append({'token': token, 'score': token_score})\n",
        "\n",
        "    # Ordenar a lista pelo score\n",
        "    nomes_lugares.sort(key=lambda x: x['score'], reverse=True)\n",
        "\n",
        "    return nomes_lugares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g7cZv-ddzwqz"
      },
      "outputs": [],
      "source": [
        "bert_pasta_few = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/v2/'\n",
        "roberta_pasta_few = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/v2/'\n",
        "electra_pasta_few = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/v2/'\n",
        "\n",
        "bert_pasta_one = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/bert/v2/'\n",
        "roberta_pasta_one = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/roberta/v2/'\n",
        "electra_pasta_one = '/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/electra/v2/'\n",
        "\n",
        "bert_pasta = '/home/rafael/tese/code/data_v2/outputs/bert/'\n",
        "roberta_pasta = '/home/rafael/tese/code/data_v2/outputs/roberta/'\n",
        "electra_pasta = '/home/rafael/tese/code/data_v2/outputs/electra/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IQ3c21up0ywA"
      },
      "outputs": [],
      "source": [
        "top_k = 10\n",
        "dados = {'token': '___', 'score': 0.0}\n",
        "lista_de_dicionarios = [dados.copy() for _ in range(top_k)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRiwoLdc0-Nk"
      },
      "source": [
        "## Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "w2V70CZwSS98"
      },
      "outputs": [],
      "source": [
        "# Born In\n",
        "bornIn_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_bornIn_t5_bert_few_shoot.csv')\n",
        "bornIn_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#bornIn = bornIn.iloc[:10]\n",
        "\n",
        "for i in bornIn_bert.columns:\n",
        "    bornIn_bert[i] = bornIn_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "bornIn_bert.to_csv(bert_pasta_few + 'outputs_bornIn_t5_bert_few_shoot_v2.csv')\n",
        "\n",
        "# DiedIn\n",
        "diedIn_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_diedIn_t5_bert_few_shoot.csv')\n",
        "diedIn_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#diedIn_bert = diedIn_bert[:10]\n",
        "for i in diedIn_bert.columns:\n",
        "    diedIn_bert[i] = diedIn_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "diedIn_bert.to_csv(bert_pasta_few + 'outputs_diedIn_t5_bert_few_shoot_v2.csv')\n",
        "\n",
        "# Capital\n",
        "capital_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_capital_t5_bert_few_shoot.csv')\n",
        "capital_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "for i in capital_bert.columns:\n",
        "    capital_bert[i] = capital_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "capital_bert.to_csv(bert_pasta_few + 'outputs_capital_t5_bert_few_shoot_v2.csv')\n",
        "\n",
        "# Worksfor\n",
        "worksfor_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_worksfor_t5_bert_few_shoot.csv')\n",
        "worksfor_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#worksfor_bert = worksfor_bert[:10]\n",
        "for i in worksfor_bert.columns:\n",
        "    worksfor_bert[i] = worksfor_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "worksfor_bert.to_csv(bert_pasta_few + 'outputs_worksfor_t5_bert_few_shoot_v2.csv')\n",
        "\n",
        "# Citizen\n",
        "citizen_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_citizen_t5_bert_few_shoot.csv')\n",
        "citizen_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#citizen_bert = citizen_bert[:10]\n",
        "for i in citizen_bert.columns:\n",
        "    citizen_bert[i] = citizen_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "citizen_bert.to_csv(bert_pasta_few + 'outputs_citizen_t5_bert_few_shoot_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language\n",
        "language_bert_one = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/bert/outputs_language_t5_bert_one_shoot.csv')\n",
        "language_bert_one.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_bert_one = language_bert_one[:10]\n",
        "for i in language_bert_one.columns:\n",
        "    language_bert_one[i] = language_bert_one[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_bert_one.to_csv(bert_pasta_one + 'outputs_language_t5_bert_one_shoot_v2.csv')\n",
        "\n",
        "# Language\n",
        "language_bert_few = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/bert/outputs_language_t5_bert_few_shoot.csv')\n",
        "language_bert_few.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_bert_few = language_bert_few[:10]\n",
        "for i in language_bert_few.columns:\n",
        "    language_bert_few[i] = language_bert_few[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_bert_few.to_csv(bert_pasta_few + 'outputs_language_t5_bert_few_shoot_v2.csv')\n",
        "\n",
        "\n",
        "# Language\n",
        "language_bert = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/bert/outputs_language_t5_bert.csv')\n",
        "language_bert.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_bert = language_bert[:10]\n",
        "for i in language_bert.columns:\n",
        "    language_bert[i] = language_bert[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_bert.to_csv(bert_pasta + 'outputs_language_bert_v2.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVJTbuVx18V6"
      },
      "source": [
        "## Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9YpvumR82u5N"
      },
      "outputs": [],
      "source": [
        "# Born In\n",
        "bornIn_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_bornIn_t5_roberta_few_shoot.csv')\n",
        "bornIn_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#bornIn = bornIn.iloc[:10]\n",
        "\n",
        "for i in bornIn_roberta.columns:\n",
        "    bornIn_roberta[i] = bornIn_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "bornIn_roberta.to_csv(roberta_pasta_few + 'outputs_bornIn_t5_roberta_few_shoot_v2.csv')\n",
        "\n",
        "# DiedIn\n",
        "diedIn_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_diedIn_t5_roberta_few_shoot.csv')\n",
        "diedIn_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#diedIn_roberta = diedIn_roberta[:10]\n",
        "for i in diedIn_roberta.columns:\n",
        "    diedIn_roberta[i] = diedIn_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "diedIn_roberta.to_csv(roberta_pasta_few + 'outputs_diedIn_t5_roberta_few_shoot_v2.csv')\n",
        "\n",
        "# Capital\n",
        "capital_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_capital_t5_roberta_few_shoot.csv')\n",
        "capital_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "for i in capital_roberta.columns:\n",
        "    capital_roberta[i] = capital_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "capital_roberta.to_csv(roberta_pasta_few + 'outputs_capital_t5_roberta_few_shoot_v2.csv')\n",
        "\n",
        "# Worksfor\n",
        "worksfor_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_worksfor_t5_roberta_few_shoot.csv')\n",
        "worksfor_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#worksfor_roberta = worksfor_roberta[:10]\n",
        "for i in worksfor_roberta.columns:\n",
        "    worksfor_roberta[i] = worksfor_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "worksfor_roberta.to_csv(roberta_pasta_few + 'outputs_worksfor_t5_roberta_few_shoot_v2.csv')\n",
        "\n",
        "# Citizen\n",
        "citizen_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_citizen_t5_roberta_few_shoot.csv')\n",
        "citizen_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#citizen_roberta = citizen_roberta[:10]\n",
        "for i in citizen_roberta.columns:\n",
        "    citizen_roberta[i] = citizen_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "citizen_roberta.to_csv(roberta_pasta_few + 'outputs_citizen_t5_roberta_few_shoot_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language\n",
        "language_roberta_one = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/roberta/outputs_language_t5_roberta_one_shoot.csv')\n",
        "language_roberta_one.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_roberta_one = language_roberta_one[:10]\n",
        "for i in language_roberta_one.columns:\n",
        "    language_roberta_one[i] = language_roberta_one[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_roberta_one.to_csv(roberta_pasta_one + 'outputs_language_t5_roberta_one_shoot_v2.csv')\n",
        "\n",
        "# Language\n",
        "language_roberta_few = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/roberta/outputs_language_t5_roberta_few_shoot.csv')\n",
        "language_roberta_few.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_roberta_few = language_roberta_few[:10]\n",
        "for i in language_roberta_few.columns:\n",
        "    language_roberta_few[i] = language_roberta_few[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_roberta_few.to_csv(roberta_pasta_few + 'outputs_language_t5_roberta_few_shoot_v2.csv')\n",
        "\n",
        "\n",
        "\n",
        "# Language\n",
        "language_roberta = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/roberta/outputs_language_t5_roberta.csv')\n",
        "language_roberta.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_roberta = language_roberta[:10]\n",
        "for i in language_roberta.columns:\n",
        "    language_roberta[i] = language_roberta[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_roberta.to_csv(roberta_pasta + 'outputs_language_roberta_v2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6JN7JyX2BgS"
      },
      "source": [
        "## Electra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Hwst7bI92xzB"
      },
      "outputs": [],
      "source": [
        "# Born In\n",
        "bornIn_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_bornIn_t5_electra_few_shoot.csv')\n",
        "bornIn_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#bornIn = bornIn.iloc[:10]\n",
        "\n",
        "for i in bornIn_electra.columns:\n",
        "    bornIn_electra[i] = bornIn_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "bornIn_electra.to_csv(electra_pasta_few + 'outputs_bornIn_t5_electra_few_shoot_v2.csv')\n",
        "\n",
        "# DiedIn\n",
        "diedIn_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_diedIn_t5_electra_few_shoot.csv')\n",
        "diedIn_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#diedIn_electra = diedIn_electra[:10]\n",
        "for i in diedIn_electra.columns:\n",
        "    diedIn_electra[i] = diedIn_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "diedIn_electra.to_csv(electra_pasta_few + 'outputs_diedIn_t5_electra_few_shoot_v2.csv')\n",
        "\n",
        "# Capital\n",
        "capital_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_capital_t5_electra_few_shoot.csv')\n",
        "capital_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "for i in capital_electra.columns:\n",
        "    capital_electra[i] = capital_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "capital_electra.to_csv(electra_pasta_few + 'outputs_capital_t5_electra_few_shoot_v2.csv')\n",
        "\n",
        "# Worksfor\n",
        "worksfor_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_worksfor_t5_electra_few_shoot.csv')\n",
        "worksfor_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#worksfor_electra = worksfor_electra[:10]\n",
        "for i in worksfor_electra.columns:\n",
        "    worksfor_electra[i] = worksfor_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "worksfor_electra.to_csv(electra_pasta_few + 'outputs_worksfor_t5_electra_few_shoot_v2.csv')\n",
        "\n",
        "# Citizen\n",
        "citizen_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_citizen_t5_electra_few_shoot.csv')\n",
        "citizen_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#citizen_electra = citizen_electra[:10]\n",
        "for i in citizen_electra.columns:\n",
        "    citizen_electra[i] = citizen_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "citizen_electra.to_csv(electra_pasta_few + 'outputs_citizen_t5_electra_few_shoot_v2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language\n",
        "language_electra_one = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/one/electra/outputs_language_t5_electra_one_shoot.csv')\n",
        "language_electra_one.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_electra_one = language_electra_one[:10]\n",
        "for i in language_electra_one.columns:\n",
        "    language_electra_one[i] = language_electra_one[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_electra_one.to_csv(electra_pasta_one + 'outputs_language_t5_electra_one_shoot_v2.csv')\n",
        "\n",
        "# Language\n",
        "language_electra_few = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/One_Few-Shoot/few/electra/outputs_language_t5_electra_few_shoot.csv')\n",
        "language_electra_few.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_electra_few = language_electra_few[:10]\n",
        "for i in language_electra_few.columns:\n",
        "    language_electra_few[i] = language_electra_few[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_electra_few.to_csv(electra_pasta_few + 'outputs_language_t5_electra_few_shoot_v2.csv')\n",
        "\n",
        "# Language\n",
        "language_electra = pd.read_csv('/home/rafael/tese/code/data/novos_data/dados/outputs/electra/outputs_language_t5_electra.csv')\n",
        "language_electra.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "#language_electra = language_electra[:10]\n",
        "for i in language_electra.columns:\n",
        "    language_electra[i] = language_electra[i].apply(lambda x: lista_de_dicionarios if pd.isna(x) else x)\n",
        "language_electra.to_csv(electra_pasta + 'outputs_language_electra_v2.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
